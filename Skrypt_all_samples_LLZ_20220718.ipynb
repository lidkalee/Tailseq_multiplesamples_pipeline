{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import filecmp\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define functions\n",
    "pattern1 = re.compile(\"GTCAG\")\n",
    "pattern_G = re.compile('[G]{2,}$')\n",
    "adapt = \"GTCAG\"\n",
    "\n",
    "def delete_Ns_before_adapter_fromR2(infile_path, outfile_path, pattern):\n",
    "    '''\n",
    "    Function removes the Ns sequence and pattern (adaptor) from the beginning of of second line of read in reads2, and move it to the header of read\n",
    "    in the form:  @header_pattern.\n",
    "    The function check length of the read and remove appropriate number of characters from fourth line of read\n",
    "    (the line with the quality of read). \n",
    "    Reads without pattern have header with \"_withoutanytail\" at the end of the end of header.\n",
    "    \n",
    "    Input:\n",
    "        infile_path: str\n",
    "        outfile_path: str\n",
    "        pattern: str\n",
    "        \n",
    "    Output: new fastq file (under output_path) withoth Ns sequence and the pattern, and truncated qualit line. \n",
    "    '''\n",
    "    with open(outfile_path, 'w') as w:\n",
    "        infile = SeqIO.parse(infile_path, \"fastq\")\n",
    "        pattern = re.compile(pattern)\n",
    "\n",
    "        for read in infile:\n",
    "            fastq = read.format(\"fastq\")\n",
    "            header = fastq.partition('\\n')[0]\n",
    "            sequence = fastq.splitlines()[1]\n",
    "            strand = fastq.splitlines()[2]\n",
    "            quality = fastq.splitlines()[3]\n",
    "            #pattern = re.compile(pattern)\n",
    "            adapter = re.search(pattern, str(sequence))\n",
    "         #   GG_seq_3prim = re.search(pattern_G, str(sequence))##\n",
    "            if adapter == None:\n",
    "                adapter1 = \"lack_of_adapter\"\n",
    "            else:\n",
    "                adapter = adapter.group(0)\n",
    "               # GG_seq_3prim = GG_seq_3prim.group(0)##\n",
    "                sequence = sequence.split(adapt, 1)[-1]\n",
    "                #sequence = \n",
    "               # NNs = sequence.split(adapt)[0]\n",
    "            \n",
    "                seq_length = len(sequence)\n",
    "                \n",
    "                quality = str(quality[-(seq_length+1) :-1])\n",
    "            #header=str(read.id) + \"_\" + NNs \n",
    "            new_read = header+'\\n'+sequence+'\\n'+strand+'\\n'+ quality+'\\n'\n",
    "            w.write(new_read)\n",
    "            \n",
    "pattern1 = re.compile(\"GTCAG\")\n",
    "pattern_G = re.compile('[G]{2,}$')\n",
    "adapt = \"GTCAG\"\n",
    "\n",
    "def move_Ns_before_adapter_fromR2_to_header(infile_path, outfile_path, pattern):\n",
    "    '''\n",
    "    Function removes the Ns sequence and pattern (adaptor) from the beginning of of second line of read in reads2, and move it to the header of read\n",
    "    in the form:  @header_pattern.\n",
    "    The function check length of the read and remove appropriate number of characters from fourth line of read\n",
    "    (the line with the quality of read). \n",
    "    Reads without pattern have header with \"_withoutanytail\" at the end of the end of header.\n",
    "    \n",
    "    Input:\n",
    "        infile_path: str\n",
    "        outfile_path: str\n",
    "        pattern: str\n",
    "        \n",
    "    Output: new fastq file (under output_path) withoth Ns sequence and the pattern, and truncated qualit line. \n",
    "    '''\n",
    "    with open(outfile_path, 'w') as w:\n",
    "        infile = SeqIO.parse(infile_path, \"fastq\")\n",
    "        pattern = re.compile(pattern)\n",
    "\n",
    "        for read in infile:\n",
    "            fastq = read.format(\"fastq\")\n",
    "            header = fastq.partition('\\n')[0]\n",
    "            sequence = fastq.splitlines()[1]\n",
    "            strand = fastq.splitlines()[2]\n",
    "            quality = fastq.splitlines()[3]\n",
    "            #pattern = re.compile(pattern)\n",
    "            adapter = re.search(pattern, str(sequence))\n",
    "            seq_raw_length = len(sequence)\n",
    "         #   GG_seq_3prim = re.search(pattern_G, str(sequence))##\n",
    "            if adapter == None:\n",
    "                adapter1 = \"lack_of_adapter\"\n",
    "                sequence_NNs = \"noNNs\"\n",
    "                header= '@'+str(read.id) + \"_\" + str(sequence_NNs)#\n",
    "                new_read = header+'\\n'+sequence+'\\n'+strand+'\\n'+ quality+'\\n'\n",
    "            else:\n",
    "                adapter = adapter.group(0)\n",
    "                sequence_NNs = sequence.split(adapt, 1)[0] \n",
    "            #GG_seq_3prim = GG_seq_3prim.group(0)##\n",
    "                sequence = sequence.split(adapt, 1)[-1]\n",
    "                \n",
    "               # NNs = sequence.split(adapt)[0]\n",
    "                seq_length = len(sequence)\n",
    "                if seq_length != seq_raw_length:\n",
    "                    quality = str(quality[-(seq_length+1) :-1])\n",
    "                else:\n",
    "                    quality = ''\n",
    "                    sequence = ''\n",
    "                header='@'+str(read.id) + \"*5NN\" + str(sequence_NNs)#\n",
    "            new_read = header+'\\n'+sequence+'\\n'+strand+'\\n'+ quality+'\\n'\n",
    "            w.write(new_read)\n",
    "            \n",
    "            \n",
    "            \n",
    "####### Function to extract tail from read sequence based on CIGAR #########\n",
    "def take_tail_fromcigar2(strand, cig, seq):\n",
    "    '''\n",
    "    Function returns tail seqence based on the CIGAR and sequence of read\n",
    "    Input:\n",
    "        cig: CIGAR from sam file after alignment qith soft-clipping  [str]\n",
    "        seq: sequence of read started from 3' end, having posibble tail   [str]\n",
    "    Output:\n",
    "        sequence of the tail extracted from read sequence based on CIGAR [str]\n",
    "    Assumptions:\n",
    "        1. For tailed reads, CIGAR starts from \\d+S (softcliping code). I's about the number\n",
    "        of softclipped nucleotides. We assume that this is also the length of the polyA tail.\n",
    "        2. Sequence seq starts from 3' tail of read.\n",
    "    '''\n",
    "\n",
    "    cigar2 = str(cig) # convert cigar to string\n",
    "    if not \"S\" in cigar2: # return nothing if CIGAR does not contain S (soft-clipping)\n",
    "        return \"\"\n",
    "    else:  # analyze data if CIGAR starts from number and S (3' soft-clipping). If not - return nothing\n",
    "        \n",
    "        \n",
    "        if strand =='-':      \n",
    "            search_result_minus = re.findall(\"[0-9]+S$\", cigar2)\n",
    "            if search_result_minus: # find CIGARs starting from 3' soft-clipping\n",
    "                number_S = int(search_result_minus[-1].split('S')[0])\n",
    "                # extract number of soft-clipped nucleotides\n",
    "                tail = seq[-number_S:] # extract tail (based of number of soft-clipped nucleotides)\n",
    "                return tail\n",
    "            else:\n",
    "                return \"\"\n",
    "        elif strand == '+':\n",
    "            search_result_plus = re.findall(\"^[0-9]+S\", cigar2)\n",
    "            if search_result_plus: # find CIGARs starting from 3' soft-clipping\n",
    "                number_S = int(cigar2.split('S')[0]) # extract number of soft-clipped nucleotides\n",
    "                tail = seq[0:number_S] # extract tail (based of number of soft-clipped nucleotides)\n",
    "                return tail\n",
    "            else:\n",
    "                return \"\"\n",
    "        else:\n",
    "             return \"\"\n",
    "        \n",
    "\n",
    "# Test the function take_tail_fromcigar():\n",
    "\n",
    "assert take_tail_fromcigar2('-', '8S', 'UUUHSAAAAAAAAAA') =='AAAAAAAA'\n",
    "assert take_tail_fromcigar2('-', '8S444M1S', 'AAAAAAAAAAUUUHS') =='S'\n",
    "assert take_tail_fromcigar2('+', '8S444M3S', 'AAAAAAAAAAUUUHS') =='AAAAAAAA'\n",
    "assert take_tail_fromcigar2('-', '67M7S', 'AAAAAAAAAAUUUHS') =='AAUUUHS'\n",
    "assert take_tail_fromcigar2('-', '*', 'AAAAAAAAAAUUUHS') ==''\n",
    "\n",
    "def def_strand(flag):\n",
    "    if flag == 4:\n",
    "        return \"unmapped\"\n",
    "    elif flag ==16:\n",
    "        return \"-\"\n",
    "    elif flag == 0:\n",
    "        return \"+\"\n",
    "    else:\n",
    "        return 'nn'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "pattern_mRNA = re.compile(\"spac|spap|spbp|spcc|spcp|spbc\")\n",
    "pattern_tRNA = re.compile(\"trna\")\n",
    "pattern_mito = re.compile(\"spmit\")\n",
    "pattern_rRNA = re.compile(\"rrna\")\n",
    "pattern_snRNA = re.compile(\"snrna\")\n",
    "pattern_snoRNA = re.compile(\"snorna\")\n",
    "pattern_ncRNA = re.compile(\"ncrna\")\n",
    "\n",
    "\n",
    "def test_RNA_type(feature_name):\n",
    "    \"\"\"tests for the type of tail \"\"\"\n",
    "    if pattern_mRNA.search(feature_name): # for example AATT\n",
    "        return \"mRNA\"\n",
    "    elif pattern_tRNA.search(feature_name): # for example AATT\n",
    "        return \"tRNA\"\n",
    "    elif pattern_mito.search(feature_name): # for example AATT\n",
    "        return \"mito_RNA\"\n",
    "    elif pattern_rRNA.search(feature_name): # for example AATT\n",
    "        return \"rRNA\"\n",
    "    elif pattern_snRNA.search(feature_name): # for example AATT\n",
    "        return \"snRNA\"\n",
    "    elif pattern_snoRNA.search(feature_name): # for example AATT\n",
    "        return \"snoRNA\"\n",
    "    elif pattern_ncRNA.search(feature_name): # for example AATT\n",
    "        return \"ncRNA\"\n",
    "    else: #only A's\n",
    "        return \"other_type\"\n",
    "\n",
    "assert test_RNA_type(\"spncrna\") == \"ncRNA\"\n",
    "assert test_RNA_type(\"sspcc\") == \"mRNA\"\n",
    "assert test_RNA_type(\"AAAAA\") == \"other_type\"\n",
    "assert test_RNA_type(\"TAATTT\") == \"other_type\"\n",
    "\n",
    "####### Function to test tail type #########\n",
    "\n",
    "pattern_polyAU_forward = re.compile(\"^A{1,}T{2,}\") # reverse transcribed\n",
    "pattern_oligoU_forward = re.compile(\"^A{1,}\")\n",
    "pattern_polyA_forward = re.compile(\"^T{3,}$\")\n",
    "\n",
    "pattern_polyAU_reverse = re.compile(\"A{1,}T{2,}$\") # reverse transcribed\n",
    "pattern_oligoU_reverse = re.compile(\"T{1,}$\")\n",
    "pattern_polyA_reverse = re.compile(\"A{3,}$\")  \n",
    "\n",
    "def test_tail(strand, tail):\n",
    "    \"\"\" Tests for the type of tail. Patterns are prepared for analysis of R2 read, reverse transcribed:\n",
    "        base sequence start from the end of polyadenylation tail at 3' end of RNA,\n",
    "        where T means adenine, and A meand uridine in the 3' tail\"\"\"\n",
    "    if len(tail) > 0:\n",
    "        if strand == '+' or strand == 'unmapped':\n",
    "            if \"A\" in tail:\n",
    "                if pattern_polyAU_forward.fullmatch(tail): \n",
    "                    return \"polyAU\"\n",
    "                elif pattern_oligoU_forward.fullmatch(tail): \n",
    "                    return \"oligoU\"\n",
    "                else:\n",
    "                    return \"mixed_tail\"\n",
    "            elif pattern_polyA_forward.fullmatch(tail):\n",
    "                    return \"polyA\"\n",
    "            else: \n",
    "                return \"mixed_tail\"\n",
    "        elif strand == '-':\n",
    "            if \"T\" in tail:\n",
    "                if pattern_polyAU_reverse.fullmatch(tail): \n",
    "                    return \"polyAU\"\n",
    "                elif pattern_oligoU_reverse.fullmatch(tail): \n",
    "                    return \"oligoU\"\n",
    "                else:\n",
    "                    return \"mixed_tail\"\n",
    "            elif pattern_polyA_reverse.fullmatch(tail):\n",
    "                    return \"polyA\"\n",
    "            else: \n",
    "                return \"mixed_tail\"\n",
    "    else:\n",
    "        return \"without_tail\"\n",
    "    \n",
    "# Test the function test_tail():\n",
    "\n",
    "assert test_tail('+', \"AATTT\") == \"polyAU\"\n",
    "assert test_tail('+', \"AAAAAA\") == \"oligoU\"\n",
    "assert test_tail('-',\"AAAAA\") == \"polyA\"\n",
    "assert test_tail('-',\"TAATTT\") == \"mixed_tail\"\n",
    "assert test_tail('+','')== \"without_tail\"\n",
    "assert test_tail('unmapped','TTT')== \"polyA\"\n",
    "\n",
    "\n",
    "def take_tail_fromcigar2(strand, cig, seq):\n",
    "    '''\n",
    "    Function returns tail seqence based on the CIGAR and sequence of read\n",
    "    Input:\n",
    "        cig: CIGAR from sam file after alignment qith soft-clipping  [str]\n",
    "        seq: sequence of read started from 3' end, having posibble tail   [str]\n",
    "    Output:\n",
    "        sequence of the tail extracted from read sequence based on CIGAR [str]\n",
    "    Assumptions:\n",
    "        1. For tailed reads, CIGAR starts from \\d+S (softcliping code). I's about the number\n",
    "        of softclipped nucleotides. We assume that this is also the length of the polyA tail.\n",
    "        2. Sequence seq starts from 3' tail of read.\n",
    "    '''\n",
    "\n",
    "    cigar2 = str(cig) # convert cigar to string\n",
    "    if not \"S\" in cigar2: # return nothing if CIGAR does not contain S (soft-clipping)\n",
    "        return \"\"\n",
    "    else:  # analyze data if CIGAR starts from number and S (3' soft-clipping). If not - return nothing\n",
    "        \n",
    "        \n",
    "        if strand =='-':      \n",
    "            search_result_minus = re.findall(\"[0-9]+S$\", cigar2)\n",
    "            if search_result_minus: # find CIGARs starting from 3' soft-clipping\n",
    "                number_S = int(search_result_minus[-1].split('S')[0])\n",
    "                # extract number of soft-clipped nucleotides\n",
    "                tail = seq[-number_S:] # extract tail (based of number of soft-clipped nucleotides)\n",
    "                return tail\n",
    "            else:\n",
    "                return \"\"\n",
    "        elif strand == '+':\n",
    "            search_result_plus = re.findall(\"^[0-9]+S\", cigar2)\n",
    "            if search_result_plus: # find CIGARs starting from 3' soft-clipping\n",
    "                number_S = int(cigar2.split('S')[0]) # extract number of soft-clipped nucleotides\n",
    "                tail = seq[0:number_S] # extract tail (based of number of soft-clipped nucleotides)\n",
    "                return tail\n",
    "            else:\n",
    "                return \"\"\n",
    "        else:\n",
    "             return \"\"\n",
    "        \n",
    "\n",
    "# Test the function take_tail_fromcigar():\n",
    "\n",
    "assert take_tail_fromcigar2('-', '8S', 'UUUHSAAAAAAAAAA') =='AAAAAAAA'\n",
    "assert take_tail_fromcigar2('-', '8S444M1S', 'AAAAAAAAAAUUUHS') =='S'\n",
    "assert take_tail_fromcigar2('+', '8S444M3S', 'AAAAAAAAAAUUUHS') =='AAAAAAAA'\n",
    "assert take_tail_fromcigar2('-', '67M7S', 'AAAAAAAAAAUUUHS') =='AAUUUHS'\n",
    "assert take_tail_fromcigar2('-', '*', 'AAAAAAAAAAUUUHS') ==''\n",
    "\n",
    "\n",
    "def grep_tail_edit(strand, seq):\n",
    "    '''\n",
    "    Function ....\n",
    "    '''\n",
    "\n",
    "    if strand =='-':      \n",
    "        search_result_minus = re.findall(\"[A]{0,}[T]{0,}$\", seq)\n",
    "        if search_result_minus: # find CIGARs starting from 3' soft-clipping\n",
    "            return search_result_minus[0]\n",
    "        else:\n",
    "            return \"\"\n",
    "    elif strand == '+' or strand == 'unmapped':\n",
    "        search_result_plus = re.findall(\"^[A]{0,}[T]{0,}\", seq)\n",
    "        if search_result_plus: # find CIGARs starting from 3' soft-clipping\n",
    "            return search_result_plus[0]\n",
    "        else:\n",
    "            return \"\"\n",
    "    else:\n",
    "        return \"\"\n",
    "        \n",
    "\n",
    "# Test the function take_tail_fromcigar():\n",
    "\n",
    "assert grep_tail_edit('-', 'UUUHSAAAAAAAAAA') =='AAAAAAAAAA'\n",
    "assert grep_tail_edit('-',  'AAAAAAAAAAUUUHS') ==''\n",
    "assert grep_tail_edit('+',  'AAAAAAAAAAUUUHS') =='AAAAAAAAAA'\n",
    "\n",
    "def tail_fromGREPorCIGAR_description(cigar, tailGrep, tailCigar):\n",
    "    if cigar == '*':\n",
    "        return 'grep'\n",
    "    else:\n",
    "        return 'cigar'\n",
    "\n",
    "\n",
    "def tail_fromGREPorCIGAR(cigar, tailGrep, tailCigar):\n",
    "    if cigar == '*':\n",
    "        return tailGrep\n",
    "    else:\n",
    "        return tailCigar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Tail-seq data using both reads, R1 and R2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of R2 reads having UMIs and adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/deltacid1_clone1_S77_R2_001.fastq.gz\r\n",
      "data/deltacid1_clone2_S78_R2_001.fastq.gz\r\n",
      "data/deltacid1deltadis32_clone1_S85_R2_001.fastq.gz\r\n",
      "data/deltacid1deltadis32_clone2_S86_R2_001.fastq.gz\r\n",
      "data/deltacid1deltadis32deltalsm1_clone1_S97_R2_001.fastq.gz\r\n",
      "data/deltacid1deltadis32deltalsm1_clone2_S98_R2_001.fastq.gz\r\n",
      "data/deltacid1deltadis32deltaski2_clone1_S99_R2_001.fastq.gz\r\n",
      "data/deltacid1deltadis32deltaski2_clone2_S100_R2_001.fastq.gz\r\n",
      "data/deltacid1deltalsm1_clone1_S87_R2_001.fastq.gz\r\n",
      "data/deltacid1deltalsm1_clone2_S88_R2_001.fastq.gz\r\n",
      "data/deltacid1deltalsm1deltaski2_clone1_S101_R2_001.fastq.gz\r\n",
      "data/deltacid1deltalsm1deltaski2_clone2_S102_R2_001.fastq.gz\r\n",
      "data/deltacid1deltaski2_clone1_S89_R2_001.fastq.gz\r\n",
      "data/deltacid1deltaski2_clone2_S90_R2_001.fastq.gz\r\n",
      "data/deltadis32_clone1_S79_R2_001.fastq.gz\r\n",
      "data/deltadis32_clone2_S80_R2_001.fastq.gz\r\n",
      "data/deltadis32deltalsm1_clone1_S91_R2_001.fastq.gz\r\n",
      "data/deltadis32deltalsm1_clone2_S92_R2_001.fastq.gz\r\n",
      "data/deltadis32deltalsm1deltaski2_clone1_S103_R2_001.fastq.gz\r\n",
      "data/deltadis32deltalsm1deltaski2_clone2_S104_R2_001.fastq.gz\r\n",
      "data/deltadis32deltaski2_clone1_S93_R2_001.fastq.gz\r\n",
      "data/deltadis32deltaski2_clone2_S94_R2_001.fastq.gz\r\n",
      "data/deltalsm1_clone1_S81_R2_001.fastq.gz\r\n",
      "data/deltalsm1_clone2_S82_R2_001.fastq.gz\r\n",
      "data/deltalsm1deltaski2_clone1_S95_R2_001.fastq.gz\r\n",
      "data/deltalsm1deltaski2_clone2_S96_R2_001.fastq.gz\r\n",
      "data/deltaski2_clone1_S83_R2_001.fastq.gz\r\n",
      "data/deltaski2_clone2_S84_R2_001.fastq.gz\r\n",
      "data/Wild_type_clone1_TS_S75_R2_001.fastq.gz\r\n",
      "data/Wild_type_clone2_TS_S76_R2_001.fastq.gz\r\n",
      "data/Wild_type_clone3_S105_R2_001.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/*_R2_001.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir R2_allsamples\n",
    "!mkdir R2_allsamples/filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: \"(\" unexpected\n",
      "/bin/sh: 1: Bad substitution\n"
     ]
    }
   ],
   "source": [
    "## NEWscript1_selectR2withUNIs.bash\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Declare an array of string with type\n",
    "declare -a StringArray=('deltacid1_clone1_S77_' 'deltacid1_clone2_S78_' 'deltacid1deltadis32_clone1_S85_' 'deltacid1deltadis32_clone2_S86_' 'deltacid1deltadis32deltalsm1_clone1_S97_' 'deltacid1deltadis32deltalsm1_clone2_S98_' 'deltacid1deltadis32deltaski2_clone1_S99_' 'deltacid1deltadis32deltaski2_clone2_S100_' 'deltacid1deltalsm1_clone1_S87_' 'deltacid1deltalsm1_clone2_S88_' 'deltacid1deltalsm1deltaski2_clone1_S101_' 'deltacid1deltalsm1deltaski2_clone2_S102_' 'deltacid1deltaski2_clone1_S89_' 'deltacid1deltaski2_clone2_S90_' 'deltadis32_clone1_S79_' 'deltadis32_clone2_S80_' 'deltadis32deltalsm1_clone1_S91_' 'deltadis32deltalsm1_clone2_S92_' 'deltadis32deltalsm1deltaski2_clone1_S103_' 'deltadis32deltalsm1deltaski2_clone2_S104_' 'deltadis32deltaski2_clone1_S93_' 'deltadis32deltaski2_clone2_S94_' 'deltalsm1_clone1_S81_' 'deltalsm1_clone2_S82_' 'deltalsm1deltaski2_clone1_S95_' 'deltalsm1deltaski2_clone2_S96_' 'deltaski2_clone1_S83_' 'deltaski2_clone2_S84_' 'Wild_type_clone1_TS_S75_' 'Wild_type_clone2_TS_S76_')\n",
    "\n",
    "# Iterate the string array using for loop\n",
    "# Gunzip R2.fastq, select reads having 5Ns and adaptor, gzip input fastq\n",
    "for val in ${StringArray[@]}; do \n",
    "\techo \"sample_${val}\"; gunzip \"data/${val}R2_001.fastq.gz\"; grep -E -A 2 -B 1 --no-group-separator '^[A-Z][A-Z][A-Z][A-Z][A-Z][A-Z]GTCAG' \"data/${val}R2_001.fastq\" > \"R2_allsamples/filter/${val}R2_withUMIs.fastq\"; gzip \"data/${val}R2_001.fastq\"; \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gunzip data/Wild_type_clone1_TS_S75_R2_001.fastq.gz\n",
    "#grep -E -A 2 -B 1 --no-group-separator '^[A-Z][A-Z][A-Z][A-Z][A-Z][A-Z]GTCAG' data/Wild_type_clone1_TS_S75_R2_001.fastq > analiza_July2022/R2/Wild_type_clone1_R2_GTCAG.fastq\n",
    "#gzip data/Wild_type_clone1_TS_S75_R2_001.fastq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all_mapped_po1nt+kopia.fastq\r\n",
      " analiza_July2022\r\n",
      "'Analiza short.ipynb'\r\n",
      " analiza_unmapped_tailed_loop\r\n",
      " background_angeli_554genes_20220311.txt\r\n",
      " bams\r\n",
      " bams_STAR\r\n",
      " BED_R2_STAR\r\n",
      " bigwigs\r\n",
      " data\r\n",
      " deltacid1_clone1_S77_tailsinheader_20220119.fastq\r\n",
      " DESEQ_LL.R\r\n",
      " empty.fastq\r\n",
      " figures\r\n",
      " gene_cluster_20220309.csv\r\n",
      " genome\r\n",
      " genome_sdsintronsutrs\r\n",
      " gff\r\n",
      " htseq\r\n",
      " htseq_merged3.csv\r\n",
      " htseq_mRNA_doDESeq2_20220113.csv\r\n",
      " image.webp\r\n",
      " kopia_all_mapped_po1nt.fastq\r\n",
      " lista_headerow.txt\r\n",
      " Log.out\r\n",
      " mRNA_tailtypes_per_strain_20220221.csv\r\n",
      " multiqc\r\n",
      " NEWscript1_selectR2withUMIs.bash\r\n",
      " output_headertoorganise.fastq\r\n",
      " pattern_in_header.fastq\r\n",
      " polyA_pivot_dropna_20220311.csv\r\n",
      " PyPolyADetector.py\r\n",
      " R1\r\n",
      " R1b.bed\r\n",
      " R1.bed\r\n",
      " R1b.sam\r\n",
      " R1.sam\r\n",
      " R1_uniqlymappedreads_20220125.csv\r\n",
      " R1_uniqlymappedreads_procent_20220125.csv\r\n",
      " R2_allsamples\r\n",
      " R2b.bed\r\n",
      " R2b.sam\r\n",
      " R2_R1_merge_sam4_PAS.csv\r\n",
      " R2_R1_wt_test_20220712.bed\r\n",
      " R2_R1_wt_test.bed\r\n",
      " R2_R2_sam3_test_20220712.csv\r\n",
      " R2_R2_sam3_test_20220713.csv\r\n",
      " R2_R2_sam3_test_20220714.csv\r\n",
      " R2_R2_sam_test_20220712.csv\r\n",
      " R2.sam\r\n",
      " R2_uniqlymappedreads_20220125.csv\r\n",
      " R2_uniqlymappedreads_procent_20220125.csv\r\n",
      " reference\r\n",
      " robocze\r\n",
      " roboczyR1\r\n",
      " salmon\r\n",
      " sample_2.fasta\r\n",
      " sams_20220217\r\n",
      " sams_R2_STAR\r\n",
      " script10_R1_gunzipR1_cutadapt_gzip.bash\r\n",
      " script12_R1_min15nt_SSD.bash\r\n",
      " script13_STAR_frombamtounmappedfastq.bash\r\n",
      " script1_gunzipR2_select_gzip.bash\r\n",
      " script2_2_min15nt.bash\r\n",
      " script2_2_min15nt_SSD.bash\r\n",
      " script2_cutadapt2ndAdaptor.bash\r\n",
      " script3_alignmentR2_BWA.bash\r\n",
      " script3_alignmentR2_BWA_copyseqlab.bash\r\n",
      " script3_alignmentR2_STAR.bash\r\n",
      " script3b_alignmentR1_STAR.bash\r\n",
      " script3c_alignmentR2_STAR_moretails.bash\r\n",
      " script3d_77_alignmentR2_STAR_20220217.bash\r\n",
      " script3d_alignmentR2_STAR_20220217.bash\r\n",
      " script3e_alignmentR2_STAR_bezintronow_20220310.bash\r\n",
      " script4b_sam2bed_lesscolumns_STAR.bash\r\n",
      " script4_sam2bed_20220217.bash\r\n",
      " script4_sam2bed_lesscolumns.bash\r\n",
      " script4_sam2bed_ssd_20220217.bash\r\n",
      " script5_HTseq.bash\r\n",
      " script6b_bezS_closest_STAR_ssd_20220219.bash\r\n",
      " script6_closest.bash\r\n",
      " script6_closest_STAR.bash\r\n",
      " script6_closest_STAR_ssd_20220219.bash\r\n",
      " script7b_sam2bam_STAR_20220217.bash\r\n",
      " script7b_sam2bam_STAR.bash\r\n",
      " script7e_sam2bam_STAR_20220310.bash\r\n",
      " script7_sam2bam.bash\r\n",
      " script8_bam2bw_20220217.bash\r\n",
      " script8_bam2bw.bash\r\n",
      " script9_computeMatrix_plotProfile_20220217.bash\r\n",
      " script9_computeMatrix_plotProfile.bash\r\n",
      " script9_computeMatrix_plotProfile_onlymRNA.bash\r\n",
      "'Shinyplot (3).pdf'\r\n",
      " Skrypt_all_samples_LLZ_20220718.ipynb\r\n",
      " Skrypt_czysty_20220708.ipynb\r\n",
      " skrypt_July2022.ipynb\r\n",
      " sss\r\n",
      " star_data\r\n",
      " STAR_Index\r\n",
      " _STARtmp\r\n",
      " TailSeq_dec2021_manysamples_miszmasz.ipynb\r\n",
      " tails_mRNA_persample.csv\r\n",
      " test_fastq_mniej\r\n",
      " test_R1R1.csv\r\n",
      " unmapped.fastq\r\n",
      " unmapped_R2.bam\r\n",
      " unmapped_R2b.bam\r\n",
      " unmapped_R2.bed\r\n",
      " unmapped_R2b.sam\r\n",
      " unmapped_R2c.bam\r\n",
      " unmapped_R2c.sam\r\n",
      " unmapped_R2d.bam\r\n",
      " unmapped_R2d.sam\r\n",
      " unmapped_R2.sam\r\n",
      " unmapped_reads1.fastq\r\n",
      " unmapped_reads.fastq\r\n",
      "'Untitled Folder'\r\n",
      " Wild_type_clone1_tailsinheader_20220120.fastq\r\n",
      " Wild_type_clone1_tailsinheader_20220120_min15.fastq\r\n",
      " Wild_type_clone1_TS_S75_tailsinheader_20220119.fastq\r\n",
      " Wild_type_clone2_TS_S76_tailsinheader_20220119.fastq\r\n",
      " Wild_type_clone2_TS_S76_tailsinheader_20220119_min15.fastq\r\n",
      " wt_clone1_tailsinheader_20220119.fastq\r\n",
      " wt_clone2_tailsinheader_20220119.fastq\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    os.system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the primer GTCAG and move UMIs to the header of reads (Python script),\n",
    "#\n",
    "#move_Ns_before_adapter_fromR2_to_header(infile_path = 'analiza_July2022/R2/Wild_type_clone1_R2_GTCAG.fastq', outfile_path = 'analiza_July2022/R2/Wild_type_clone1_R2_UMIinhHeader.fastq', pattern = 'GTCAG')\n",
    "#usuwanie umi i NNs\n",
    "names = ['deltacid1_clone1_S77_',  'deltacid1_clone2_S78_',  'deltacid1deltadis32_clone1_S85_',  \n",
    "         'deltacid1deltadis32_clone2_S86_',  'deltacid1deltadis32deltalsm1_clone1_S97_',  \n",
    "         'deltacid1deltadis32deltalsm1_clone2_S98_',  'deltacid1deltadis32deltaski2_clone1_S99_',  \n",
    "         'deltacid1deltadis32deltaski2_clone2_S100_',  'deltacid1deltalsm1_clone1_S87_',  \n",
    "         'deltacid1deltalsm1_clone2_S88_',  'deltacid1deltalsm1deltaski2_clone1_S101_',  \n",
    "         'deltacid1deltalsm1deltaski2_clone2_S102_',  'deltacid1deltaski2_clone1_S89_',  \n",
    "         'deltacid1deltaski2_clone2_S90_',  'deltadis32_clone1_S79_',  'deltadis32_clone2_S80_',  \n",
    "         'deltadis32deltalsm1_clone1_S91_',  'deltadis32deltalsm1_clone2_S92_',  \n",
    "         'deltadis32deltalsm1deltaski2_clone1_S103_',  'deltadis32deltalsm1deltaski2_clone2_S104_',  \n",
    "         'deltadis32deltaski2_clone1_S93_',  'deltadis32deltaski2_clone2_S94_',  'deltalsm1_clone1_S81_',  \n",
    "         'deltalsm1_clone2_S82_',  'deltalsm1deltaski2_clone1_S95_',  'deltalsm1deltaski2_clone2_S96_', \n",
    "         'deltaski2_clone1_S83_',  'deltaski2_clone2_S84_',  'Wild_type_clone1_TS_S75_', \n",
    "         'Wild_type_clone2_TS_S76_']\n",
    "\n",
    "for name in names:\n",
    "    print(name)\n",
    "    delete_Ns_before_adapter_fromR2(infile_path = 'R2_allsamples/filter/{}R2_withUMIs.fastq'.format(name),   outfile_path = 'R2_allsamples/filter/{}R2_removedUMIs.fastq'.format(name),    \n",
    "                                    pattern = 'GTCAG')\n",
    "   # os.system('rm R2_allsamples/filter/{}R2_withUMIs.fastq'.format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm R2_allsamples/filter/*_withUMIs.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of R1 reads based on R2 reads having adaptors - fast-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'R2_allsamples/filter/deltacid1_clone1_S77_R2_allsamples/filter/deltacid1_clone1_S77_R2_removedUMIs.fastq.paired.fq': No such file or directory\r\n",
      "rm: cannot remove 'R2_allsamples/filter/deltacid1_clone1_S77_R2_removedUMIs.fastq.single.fq': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "###########TEST##########################\n",
    "\n",
    "## NEWscript2_selectR1fromR2_fastpair.bash\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Declare an array of string with type\n",
    "#declare -a StringArray=('deltacid1_clone1_S77_' 'deltacid1_clone2_S78_' 'deltacid1deltadis32_clone1_S85_' 'deltacid1deltadis32_clone2_S86_' 'deltacid1deltadis32deltalsm1_clone1_S97_' 'deltacid1deltadis32deltalsm1_clone2_S98_' 'deltacid1deltadis32deltaski2_clone1_S99_' 'deltacid1deltadis32deltaski2_clone2_S100_' 'deltacid1deltalsm1_clone1_S87_' 'deltacid1deltalsm1_clone2_S88_' 'deltacid1deltalsm1deltaski2_clone1_S101_' 'deltacid1deltalsm1deltaski2_clone2_S102_' 'deltacid1deltaski2_clone1_S89_' 'deltacid1deltaski2_clone2_S90_' 'deltadis32_clone1_S79_' 'deltadis32_clone2_S80_' 'deltadis32deltalsm1_clone1_S91_' 'deltadis32deltalsm1_clone2_S92_' 'deltadis32deltalsm1deltaski2_clone1_S103_' 'deltadis32deltalsm1deltaski2_clone2_S104_' 'deltadis32deltaski2_clone1_S93_' 'deltadis32deltaski2_clone2_S94_' 'deltalsm1_clone1_S81_' 'deltalsm1_clone2_S82_' 'deltalsm1deltaski2_clone1_S95_' 'deltalsm1deltaski2_clone2_S96_' 'deltaski2_clone1_S83_' 'deltaski2_clone2_S84_' 'Wild_type_clone1_TS_S75_' 'Wild_type_clone2_TS_S76_')\n",
    "\n",
    "# Iterate the string array using for loop\n",
    "# Gunzip R2.fastq, select reads having 5Ns and adaptor, gzip input fastq\n",
    "!for val in 'deltacid1_clone1_S77_'; do rm \"R2_allsamples/filter/${val}R2_removedUMIs.fastq\" \"R2_allsamples/filter/${val}R2_allsamples/filter/${val}R2_removedUMIs.fastq.paired.fq\" \"R2_allsamples/filter/${val}R2_removedUMIs.fastq.single.fq\"; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEWscript2_selectR1fromR2_fastpair.bash\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Declare an array of string with type\n",
    "declare -a StringArray=('deltacid1_clone1_S77_' 'deltacid1_clone2_S78_' 'deltacid1deltadis32_clone1_S85_' 'deltacid1deltadis32_clone2_S86_' 'deltacid1deltadis32deltalsm1_clone1_S97_' 'deltacid1deltadis32deltalsm1_clone2_S98_' 'deltacid1deltadis32deltaski2_clone1_S99_' 'deltacid1deltadis32deltaski2_clone2_S100_' 'deltacid1deltalsm1_clone1_S87_' 'deltacid1deltalsm1_clone2_S88_' 'deltacid1deltalsm1deltaski2_clone1_S101_' 'deltacid1deltalsm1deltaski2_clone2_S102_' 'deltacid1deltaski2_clone1_S89_' 'deltacid1deltaski2_clone2_S90_' 'deltadis32_clone1_S79_' 'deltadis32_clone2_S80_' 'deltadis32deltalsm1_clone1_S91_' 'deltadis32deltalsm1_clone2_S92_' 'deltadis32deltalsm1deltaski2_clone1_S103_' 'deltadis32deltalsm1deltaski2_clone2_S104_' 'deltadis32deltaski2_clone1_S93_' 'deltadis32deltaski2_clone2_S94_' 'deltalsm1_clone1_S81_' 'deltalsm1_clone2_S82_' 'deltalsm1deltaski2_clone1_S95_' 'deltalsm1deltaski2_clone2_S96_' 'deltaski2_clone1_S83_' 'deltaski2_clone2_S84_' 'Wild_type_clone1_TS_S75_' 'Wild_type_clone2_TS_S76_')\n",
    "\n",
    "# Iterate the string array using for loop\n",
    "# Gunzip R2.fastq, select reads having 5Ns and adaptor, gzip input fastq\n",
    "for val in ${StringArray[@]}; do \n",
    "\techo \"sample_${val}\"; gunzip \"data/${val}R1_001.fastq.gz\"; fastq_pair \"data/${val}R1_001.fastq\" \"R2_allsamples/filter/${val}R2_removedUMIs.fastq\"; gzip \"data/${val}R1_001.fastq\"; rm \"data/${val}R1_001.fastq.single.fq\" \"R2_allsamples/filter/${val}R2_removedUMIs.fastq\" \"R2_allsamples/filter/${val}R2_allsamples/filter/${val}R2_removedUMIs.fastq.paired.fq\" \"R2_allsamples/filter/${val}R2_removedUMIs.fastq.single.fq\"; \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip data/*R1_001.fastq.*.fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cp data/Wild_type_clone1_TS_S75_R1_001.fastq.gz analiza_July2022/R1/\n",
    "#gunzip  analiza_July2022/R1/Wild_type_clone1_TS_S75_R1_001.fastq.gz#\n",
    "#fastq_pair analiza_July2022/R1/Wild_type_clone1_TS_S75_R1_001.fastq analiza_July2022/R2/Wild_type_clone1_R2_GTCAG.fastq\n",
    "#Interesuje nas teraz plik: analiza_July2022/R1/Wild_type_clone1_TS_S75_R1_001.fastq.paired.fq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of R1 to transcriptome using salmon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir R2_allsamples/alignmentR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare index \n",
    "salmon index -t salmon/cds+introns+utrs.fa.gz -i salmon/pombe_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment\n",
    "\n",
    "#salmon quant -i salmon/pombe_index -l MSF -r analiza_July2022/R1/Wild_type_clone1_TS_S75_R1_001.fastq.paired_cdpt2_min15.fastq.gz   -p 8 --validateMappings -o salmon/quants/Wild_type_clone1_TS_S75_quant  --writeMappings salmon/quants/Wild_type_clone1_TS_S75.sam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEWscript3_alignmentR1_salmon.bash\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Declare an array of string with type\n",
    "declare -a StringArray=('deltacid1_clone1_S77_' 'deltacid1_clone2_S78_' 'deltacid1deltadis32_clone1_S85_' 'deltacid1deltadis32_clone2_S86_' 'deltacid1deltadis32deltalsm1_clone1_S97_' 'deltacid1deltadis32deltalsm1_clone2_S98_' 'deltacid1deltadis32deltaski2_clone1_S99_' 'deltacid1deltadis32deltaski2_clone2_S100_' 'deltacid1deltalsm1_clone1_S87_' 'deltacid1deltalsm1_clone2_S88_' 'deltacid1deltalsm1deltaski2_clone1_S101_' 'deltacid1deltalsm1deltaski2_clone2_S102_' 'deltacid1deltaski2_clone1_S89_' 'deltacid1deltaski2_clone2_S90_' 'deltadis32_clone1_S79_' 'deltadis32_clone2_S80_' 'deltadis32deltalsm1_clone1_S91_' 'deltadis32deltalsm1_clone2_S92_' 'deltadis32deltalsm1deltaski2_clone1_S103_' 'deltadis32deltalsm1deltaski2_clone2_S104_' 'deltadis32deltaski2_clone1_S93_' 'deltadis32deltaski2_clone2_S94_' 'deltalsm1_clone1_S81_' 'deltalsm1_clone2_S82_' 'deltalsm1deltaski2_clone1_S95_' 'deltalsm1deltaski2_clone2_S96_' 'deltaski2_clone1_S83_' 'deltaski2_clone2_S84_' 'Wild_type_clone1_TS_S75_' 'Wild_type_clone2_TS_S76_')\n",
    "\n",
    "# Iterate the string array using for loop\n",
    "# Align R1 using salmon. Generate counttable and sam file as output.\n",
    "for val in ${StringArray[@]}; do \n",
    "\techo \"sample_${val}\"; salmon quant -i salmon/pombe_index -l MSF -r  \"data/${val}_R1_001.fastq.paired.fq.gz\" -p 8 --validateMappings -o \"R2_allsamples/alignmentR1/${val}R1_quant\"  --writeMappings \"R2_allsamples/alignmentR1/${val}R1_salmon.sam\"; \n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of mapped R1 reads, and converting sam to bam, and then to fastq\n",
    "samtools view -h -o salmon/quants/Wild_type_clone1_TS_S75.bam salmon/quants/Wild_type_clone1_TS_S75.sam\n",
    "samtools view -b -F 4 salmon/quants/Wild_type_clone1_TS_S75.bam > salmon/quants/Wild_type_clone1_TS_S75_mapped.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of reads R2, which mapped to R1 with salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_pair salmon/quants/Wild_type_clone1_TS_S75_mapped.fastq analiza_July2022/R2/Wild_type_clone1_R2_GTCAG.fastq\n",
    "#important output: analiza_July2022/R2/Wild_type_clone1_R2_GTCAG.fastq.paired.fq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of selected R2 with STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation of data \n",
    " move_Ns_before_adapter_fromR2_to_header(infile_path = 'analiza_July2022/R2/Wild_type_clone1_R2_GTCAG.fastq.paired.fq',\n",
    "                                         outfile_path = 'analiza_July2022/R2/Wild_type_clone1_R2_movedUMIS.fq', pattern = 'GTCAG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alignment\n",
    "STAR --genomeDir genome/ --readFilesIn analiza_July2022/R2/Wild_type_clone1_R2_movedUMIS.fq --alignIntronMax 1000 --outSAMtype BAM Unsorted --outFileNamePrefix analiza_July2022/R2/Wild_type_clone1_R2_tylkozmapzR1_UMIinheader_ –outFilterMultimapNmax 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selekcja odczytów R2, które mają zmapowane odpowiedniki w R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " move_Ns_before_adapter_fromR2_to_header(infile_path = 'analiza_July2022/R2/Wild_type_clone1_R2_GTCAG.fastq.paired.fq',\n",
    "                                         outfile_path = 'analiza_July2022/R2/Wild_type_clone1_R2_movedUMIS.fq', pattern = 'GTCAG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of R2 reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!STAR --genomeDir genome/ --readFilesIn analiza_July2022/R2/Wild_type_clone1_R2_movedUMIS.fq --alignIntronMax 1000 --outSAMtype BAM Unsorted --outFileNamePrefix analiza_July2022/R2/Wild_type_clone1_R2_tylkozmapzR1_UMIinheader_ –outFilterMultimapNmax 1 --outSAMunmapped Within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down stream data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools view -h -o analiza_July2022/R2/Wild_type_clone1_R2_tylkozmapzR1_UMIinheader_Aligned.out.sam analiza_July2022/R2/Wild_type_clone1_R2_tylkozmapzR1_UMIinheader_Aligned.out.bam\n",
    "\n",
    "#sam to bed\n",
    "!sam2bed < analiza_July2022/R2/Wild_type_clone1_R2_tylkozmapzR1_UMIinheader_Aligned.out.sam > analiza_July2022/R2/Wild_type_clone1_R2_tylkozmapzR1_UMIinheader_Aligned.out.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wersja z bed zamiast z sam\n",
    "!awk -F\"\\t\" '{print $1,$2,$3,$4,$6,$8,$9,$12}' analiza_July2022/R2/Wild_type_clone1_R2_tylkozmapzR1_UMIinheader_Aligned.out.bed > R2b.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_sam = pd.read_csv('R2b.sam', sep = ' ',names=['readID', 'flag', 'chr','coord', 'num', 'cigar', 'seq'])\n",
    "r2_sam = r2_sam[(r2_sam['flag']<200)]\n",
    "r2_sam['strand'] = r2_sam['flag'].apply(lambda x: def_strand(x))\n",
    "r2_sam['UMIs'] = r2_sam['readID'].apply(lambda x: x.split('*5NN')[-1])\n",
    "r2_sam['UMIs_seq'] = r2_sam['UMIs'] + '_' + r2_sam['seq']\n",
    "\n",
    "r2_sam['readID'] = r2_sam['readID'].apply(lambda x: x.split('*5NN')[0])\n",
    "r2_sam  = r2_sam.drop(columns = ['flag'])\n",
    "#r2_sam.drop_duplicates()\n",
    "r2_sam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_bed = pd.read_csv('R2b.bed', sep = ' ',names=['chr','start', 'stop','readID', 'strand','cigar','*', 'seq'])\n",
    "r2_bed['start_read'] = r2_bed['start']\n",
    "r2_bed['stop_read'] = r2_bed['stop']\n",
    "r2_bed['readID'] = r2_bed['readID'].apply(lambda x: x.split('*5NN')[0])\n",
    "r2_bed = r2_bed.drop(columns=['chr', 'start', 'stop','strand', 'cigar', '*', 'seq'])\n",
    "r2_bed = r2_bed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R1\n",
    "!grep A00805 salmon/quants/Wild_type_clone1_TS_S75.sam > R1.sam\n",
    "!sam2bed < R1.sam > R1.bed\n",
    "!awk -F\"\\t\" '{print $1,$4,$6,$7}' R1.bed > R1b.bed\n",
    "!awk -F\"\\t\" '{print $1,$2,$3}' R1.sam > R1b.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_bed = pd.read_csv('R1b.bed', sep = ' ',names=['gene','readID','strand','flag_R1'])\n",
    "r1_bed = r1_bed[r1_bed['flag_R1']<2000]\n",
    "r1_bed.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head reference/newSP.bed\n",
    "reference_newSP = pd.read_csv('reference/newSP.bed', names=['chr', 'start', 'stop', 'gene','1','2','3',\n",
    "                                                           '4', '5', '6'], sep = '\\t')\n",
    "\n",
    "reference_newSP = reference_newSP.drop(columns=['1','2','3','4', '5', '6'])\n",
    "reference_newSP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_sam = pd.read_csv('R1b.sam', sep = ' ',names=['readID','flag_R1', 'gene_R1'])\n",
    "r1_sam_bezzbednychflag = r1_sam[r1_sam['flag_R1']<2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = r2_sam.drop(columns=[  'num'])\n",
    "r3 = r3.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_R1_merge_sam = pd.merge(r3, r1_bed, on = ['readID'])\n",
    "#R2_R1_merge_sam2 = pd.merge(R2_R1_merge_sam, r2_bed, on = ['readID'])\n",
    "R2_R1_merge_sam2 = R2_R1_merge_sam.drop_duplicates()\n",
    "R2_R1_merge_sam2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_R1_merge_sam2['RNA_type'] = R2_R1_merge_sam2['gene'].apply(lambda x: test_RNA_type(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_R1_merge_sam2['tail_fromcigar'] = R2_R1_merge_sam2.apply(lambda kol: take_tail_fromcigar2(kol.strand_y, kol.cigar,kol.seq), axis = 1)\n",
    "R2_R1_merge_sam2['tail_fromGREP'] = R2_R1_merge_sam2.apply(lambda kol: grep_tail_edit(kol.strand_y,  kol.seq), axis = 1)\n",
    "R2_R1_merge_sam2['tail_type_CIGAR'] = R2_R1_merge_sam2.apply(lambda kol: test_tail(kol.strand_y, kol.tail_fromcigar), axis = 1)\n",
    "R2_R1_merge_sam2['tail_len_CIGAR'] = R2_R1_merge_sam2['tail_fromcigar'].apply(lambda x: len(x))\n",
    "R2_R1_merge_sam2['tail_type_GREP'] = R2_R1_merge_sam2.apply(lambda kol: test_tail(kol.strand_y, kol.tail_fromGREP), axis = 1)\n",
    "R2_R1_merge_sam2['tail_len_GREP'] = R2_R1_merge_sam2['tail_fromGREP'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_R1_merge_sam2 = R2_R1_merge_sam2.drop(columns=['cigar'])\n",
    "R2_R1_merge_sam2 = R2_R1_merge_sam2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_R1_merge_sam2['tail_GreporCigar'] = R2_R1_merge_sam2.apply(lambda kol: tail_fromGREPorCIGAR(kol.cigar, kol.tail_fromGREP,kol.tail_fromcigar), axis = 1)\n",
    "R2_R1_merge_sam2['tail_from'] = R2_R1_merge_sam2.apply(lambda kol: tail_fromGREPorCIGAR_description(kol.cigar, kol.tail_fromGREP,kol.tail_fromcigar), axis = 1)\n",
    "R2_R1_merge_sam3 = pd.merge(R2_R1_merge_sam2,reference_newSP,on = ['gene'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..._to_csv('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_R1_merge_sam3_in = R2_R1_merge_sam2.set_index('readID')\n",
    "r2_bed_in = r2_bed.set_index('readID')\n",
    "\n",
    "R2_R1_merge_sam4 = R2_R1_merge_sam3_in.join(r2_bed_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_seq_plus = R2_R1_merge_sam4[R2_R1_merge_sam4['strand_y'] == '+']\n",
    "closest_seq_minus = R2_R1_merge_sam4[R2_R1_merge_sam4['strand_y'] == '-']\n",
    "\n",
    "closest_seq_plus['distance'] = -(closest_seq_plus['stop'] - closest_seq_plus['stop_read'])\n",
    "closest_seq_minus['distance'] = -(closest_seq_minus['start_read'] - closest_seq_minus['start'])\n",
    "\n",
    "R2_R1_merge_sam4_PAS = pd.concat([closest_seq_minus, closest_seq_plus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
